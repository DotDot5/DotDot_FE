import { NextResponse } from 'next/server';
import { SpeechClient } from '@google-cloud/speech';
import { Storage } from '@google-cloud/storage';

export const dynamic = 'force-dynamic';
export const maxDuration = 300;

const backendBaseUrl = process.env.BACKEND_API_URL || 'http://localhost:8080';

// â­ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
function formatSecondsToMinutesSeconds(totalSeconds: number): string {
  if (totalSeconds < 0) totalSeconds = 0;
  const hours = Math.floor(totalSeconds / 3600);
  const minutes = Math.floor((totalSeconds % 3600) / 60);
  const seconds = Math.floor(totalSeconds % 60);
  return `${String(hours).padStart(2, '0')}:${String(minutes).padStart(2, '0')}:${String(
    seconds
  ).padStart(2, '0')}`;
}

function getGoogleCredentials() {
  if (process.env.GOOGLE_APPLICATION_CREDENTIALS_JSON) {
    return {
      credentials: JSON.parse(process.env.GOOGLE_APPLICATION_CREDENTIALS_JSON),
    };
  }

  if (process.env.GCS_PROJECT_ID && process.env.GCS_CLIENT_EMAIL && process.env.GCS_PRIVATE_KEY) {
    return {
      projectId: process.env.GCS_PROJECT_ID,
      credentials: {
        client_email: process.env.GCS_CLIENT_EMAIL,
        private_key: process.env.GCS_PRIVATE_KEY.replace(/\\n/g, '\n'),
      },
    };
  }

  if (process.env.GOOGLE_APPLICATION_CREDENTIALS) {
    return {
      keyFilename: process.env.GOOGLE_APPLICATION_CREDENTIALS,
    };
  }

  throw new Error('Google Cloud credentials not configured');
}

function getEncodingFromUri(gcsUri: string): string {
  const extension = gcsUri.split('.').pop()?.toLowerCase() || 'webm';
  const encodingMap: { [key: string]: string } = {
    webm: 'WEBM_OPUS',
    opus: 'WEBM_OPUS',
    mp3: 'MP3',
    mpeg: 'MP3',
    mp4: 'MP3',
    m4a: 'MP3',
    wav: 'LINEAR16',
    flac: 'FLAC',
    ogg: 'OGG_OPUS',
  };
  return encodingMap[extension] || 'WEBM_OPUS';
}

interface Segment {
  speaker: number;
  text: string;
  startTime: string;
  endTime: string;
  startTimeInSeconds: number;
  endTimeInSeconds: number;
}

// â­â­ í•µì‹¬: ë‹¨ì¼ ì²­í¬ STT ì²˜ë¦¬
async function processChunkSTT(
  speechClient: SpeechClient,
  gcsUri: string,
  offsetSeconds: number = 0
): Promise<{ segments: Segment[]; transcript: string }> {
  console.log(`ğŸ¤ STT ì‹œì‘: ${gcsUri} (offset: ${offsetSeconds}s)`);

  const encoding = getEncodingFromUri(gcsUri);
  const audio = { uri: gcsUri };

  const config = {
    encoding: encoding as any,
    sampleRateHertz: 48000,
    languageCode: 'ko-KR',
    model: 'latest_long',
    enableAutomaticPunctuation: true,
    enableWordTimeOffsets: true,
    audioChannelCount: 2,
    enableSeparateRecognitionPerChannel: false,
    useEnhanced: true,
    metadata: {
      interactionType: 'DISCUSSION',
      microphoneDistance: 'NEARFIELD',
      recordingDeviceType: 'PC',
    },
  };

  console.log('ğŸš€ Starting Google STT...');
  const [operation] = await speechClient.longRunningRecognize({ config, audio });

  console.log('â³ Waiting for STT completion...');
  const [response] = await operation.promise();

  console.log('âœ… STT completed, processing segments...'); // â­ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ì¶œ

  const segments: Segment[] = [];
  let currentSpeaker: number | null = null;
  let currentSegmentText = '';
  let currentSegmentStartTime: number | null = null;
  let lastWordEndTime: number = 0;

  response.results?.forEach((result) => {
    result.alternatives?.[0]?.words?.forEach((wordInfo) => {
      const speakerTag = wordInfo.speakerTag ?? 1;
      const word = wordInfo.word; // ì‹œê°„ ê³„ì‚°

      const startSeconds = parseInt((wordInfo.startTime?.seconds as string) || '0', 10);
      const startNanos = wordInfo.startTime?.nanos || 0;
      let startTimeInSeconds = startSeconds + startNanos / 1_000_000_000;

      const endSeconds = parseInt((wordInfo.endTime?.seconds as string) || '0', 10);
      const endNanos = wordInfo.endTime?.nanos || 0;
      let endTimeInSeconds = endSeconds + endNanos / 1_000_000_000; // â­ offset ì ìš© (ì²­í¬ì˜ ì‹œì‘ ì‹œê°„ ë”í•˜ê¸°)

      startTimeInSeconds += offsetSeconds;
      endTimeInSeconds += offsetSeconds; // ì¹¨ë¬µ êµ¬ê°„ ê³„ì‚° (5ì´ˆ ì´ìƒì´ë©´ ìƒˆ ì„¸ê·¸ë¨¼íŠ¸)

      const silenceDuration = lastWordEndTime > 0 ? startTimeInSeconds - lastWordEndTime : 0; // í™”ì ë³€ê²½ ë˜ëŠ” ê¸´ ì¹¨ë¬µ â†’ ìƒˆ ì„¸ê·¸ë¨¼íŠ¸

      if (currentSpeaker === null || speakerTag !== currentSpeaker || silenceDuration >= 5) {
        if (
          currentSegmentText !== '' &&
          currentSpeaker !== null &&
          currentSegmentStartTime !== null
        ) {
          segments.push({
            speaker: currentSpeaker,
            text: currentSegmentText.trim(),
            startTime: formatSecondsToMinutesSeconds(currentSegmentStartTime),
            endTime: formatSecondsToMinutesSeconds(lastWordEndTime),
            startTimeInSeconds: currentSegmentStartTime,
            endTimeInSeconds: lastWordEndTime,
          });
        }
        currentSpeaker = speakerTag;
        currentSegmentText = `${word} `;
        currentSegmentStartTime = startTimeInSeconds;
      } else {
        currentSegmentText += `${word} `;
      }
      lastWordEndTime = endTimeInSeconds;
    });
  }); // ë§ˆì§€ë§‰ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€

  if (currentSegmentText !== '' && currentSpeaker !== null && currentSegmentStartTime !== null) {
    segments.push({
      speaker: currentSpeaker,
      text: currentSegmentText.trim(),
      startTime: formatSecondsToMinutesSeconds(currentSegmentStartTime),
      endTime: formatSecondsToMinutesSeconds(lastWordEndTime),
      startTimeInSeconds: currentSegmentStartTime,
      endTimeInSeconds: lastWordEndTime,
    });
  } // â­ í…ìŠ¤íŠ¸ ì •ë¦¬

  const processedSegments = segments.map((s) => {
    const processedText = s.text.replace(/\s/g, '').replace(/â–/g, ' ');
    return { ...s, text: processedText };
  });

  const fullTranscript = processedSegments
    .map((s) => `[ì‚¬ìš©ì ${s.speaker}] (${s.startTime} - ${s.endTime}) ${s.text}`)
    .join('\n');

  console.log(`ğŸ“ Transcript length: ${fullTranscript.length} characters`);

  return {
    segments: processedSegments,
    transcript: fullTranscript,
  };
}

// â­â­ POST: STT ì²˜ë¦¬
export async function POST(req: Request) {
  const authorizationHeader = req.headers.get('authorization');
  console.log('ğŸ¬ STT API called');

  let speechClient: SpeechClient;

  try {
    const googleCreds = getGoogleCredentials();
    speechClient = new SpeechClient(googleCreds);
    console.log('âœ… Google Cloud client initialized');
  } catch (err) {
    console.error('âŒ Failed to initialize Google Cloud client:', err);
    return NextResponse.json(
      { error: 'Server authentication failed. Please check Google Cloud credentials.' },
      { status: 500 }
    );
  }

  const bucketName = process.env.GOOGLE_CLOUD_STORAGE_BUCKET;

  if (!bucketName) {
    console.error('âŒ GOOGLE_CLOUD_STORAGE_BUCKET not set');
    return NextResponse.json(
      { error: 'Server configuration error: GCS bucket name is missing.' },
      { status: 500 }
    );
  }

  try {
    const body = await req.json();
    const { audioId, meetingId, duration, initialRecordingOffsetSeconds = 0, meetingMethod } = body;

    if (!audioId) {
      console.error('âŒ audioId not provided');
      return NextResponse.json({ error: 'Audio ID not provided.' }, { status: 400 });
    }

    if (!meetingId) {
      console.error('âŒ meetingId not provided');
      return NextResponse.json({ error: 'Meeting ID not provided.' }, { status: 400 });
    }

    const meetingIdNum = parseInt(String(meetingId), 10);
    if (isNaN(meetingIdNum)) {
      console.error('âŒ Invalid meetingId');
      return NextResponse.json({ error: 'Invalid Meeting ID.' }, { status: 400 });
    }

    const gcsUri = audioId.startsWith('gs://') ? audioId : `gs://${bucketName}/${audioId}`;
    console.log(`ğŸ“ GCS URI: ${gcsUri}`);
    console.log(`ğŸ“Š Mode: ${meetingMethod || 'NORMAL'}, Offset: ${initialRecordingOffsetSeconds}s`); // â­â­ CHUNK ëª¨ë“œ: ë‹¨ì¼ ì²­í¬ STT ì²˜ë¦¬

    if (meetingMethod === 'CHUNK') {
      console.log('ğŸ”¹ CHUNK mode: Processing single chunk');

      const { segments, transcript } = await processChunkSTT(
        speechClient,
        gcsUri,
        initialRecordingOffsetSeconds
      );

      console.log('âœ… Chunk processing completed'); // â­ ì¦‰ì‹œ ê²°ê³¼ ë°˜í™˜ (DB ì €ì¥ ì•ˆ í•¨)

      return NextResponse.json(
        {
          transcript,
          speechLogs: segments.map((s) => ({
            speakerIndex: s.speaker,
            text: s.text,
            startTime: Math.floor(s.startTimeInSeconds),
            endTime: Math.floor(s.endTimeInSeconds),
          })),
          success: true,
        },
        { status: 200 }
      );
    } // â­â­ NORMAL/RECORD ëª¨ë“œ: ì „ì²´ íŒŒì¼ ì²˜ë¦¬ + DB ì €ì¥

    console.log('ğŸ”¹ NORMAL mode: Processing full audio');

    const { segments, transcript } = await processChunkSTT(speechClient, gcsUri, 0);

    console.log('âœ… Full audio processing completed'); // ë§ˆì§€ë§‰ ì„¸ê·¸ë¨¼íŠ¸ë¡œ duration ê³„ì‚°

    const lastSegment = segments[segments.length - 1];
    let durationToSave = lastSegment ? Math.floor(lastSegment.endTimeInSeconds) : 0;

    if (durationToSave === 0 && duration) {
      durationToSave = Math.floor(parseFloat(String(duration)));
    }

    console.log(`ğŸ’¾ Saving to DB (duration: ${durationToSave}s)`); // â­ ë°±ì—”ë“œ DB ì €ì¥

    const updateBackendUrl = `${process.env.NEXT_PUBLIC_API_BASE_URL}/api/v1/meetings/${meetingIdNum}/stt-result`;

    const requestBody = {
      duration: durationToSave,
      transcript,
      audio_id: gcsUri,
      speechLogs: segments.map((s) => ({
        speakerIndex: s.speaker,
        text: s.text,
        startTime: Math.floor(s.startTimeInSeconds),
        endTime: Math.floor(s.endTimeInSeconds),
      })),
    };

    console.log(`ğŸ“¤ Sending to backend: ${updateBackendUrl}`);

    const updateResponse = await fetch(updateBackendUrl, {
      method: 'PUT',
      headers: {
        'Content-Type': 'application/json',
        Authorization: authorizationHeader || '',
      },
      body: JSON.stringify(requestBody),
    });

    if (!updateResponse.ok) {
      const errorData = await updateResponse
        .json()
        .catch(() => ({ message: 'Unknown backend error' }));
      console.error('âŒ Backend update failed:', updateResponse.status, errorData);
      throw new Error(
        errorData.message ||
          `Backend DB update failed: ${updateResponse.status} ${updateResponse.statusText}`
      );
    }

    console.log('âœ… Successfully saved to DB');

    return NextResponse.json(
      {
        message: 'ìŒì„± ë¶„ì„ ì™„ë£Œ. ê²°ê³¼ê°€ DBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.',
        success: true,
      },
      { status: 200 }
    );
  } catch (apiError) {
    console.error('âŒ STT API error:', apiError);
    return NextResponse.json(
      { error: `An error occurred during speech analysis: ${(apiError as Error).message}` },
      { status: 500 }
    );
  }
}

// â­ GET: STT ê²°ê³¼ ì¡°íšŒ
export async function GET(request: Request) {
  const { searchParams } = new URL(request.url);
  const sttResultId = searchParams.get('sttResultId');
  const authorizationHeader = request.headers.get('authorization');

  if (!sttResultId) {
    return NextResponse.json({ error: 'STT Result IDê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.' }, { status: 400 });
  }

  try {
    const meetingId = parseInt(sttResultId, 10);
    if (isNaN(meetingId)) {
      return NextResponse.json({ error: 'ìœ íš¨í•˜ì§€ ì•Šì€ STT Result IDì…ë‹ˆë‹¤.' }, { status: 400 });
    }

    const backendUrl = `${process.env.NEXT_PUBLIC_API_BASE_URL}/api/v1/meetings/${meetingId}/stt-result`;

    console.log(`[GET /api/transcribe] ë°±ì—”ë“œ URL: ${backendUrl}`);

    const response = await fetch(backendUrl, {
      method: 'GET',
      headers: {
        Authorization: authorizationHeader || '',
      },
    });

    if (!response.ok) {
      const errorData = await response.json();
      console.error('ë°±ì—”ë“œ GET ìš”ì²­ ì‹¤íŒ¨:', errorData);
      return NextResponse.json(errorData, { status: response.status });
    }

    const data = await response.json();
    return NextResponse.json(data);
  } catch (error) {
    console.error('API ë¼ìš°íŠ¸ì—ì„œ ì˜¤ë¥˜ ë°œìƒ:', error);
    return NextResponse.json(
      { error: 'STT ê²°ê³¼ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' },
      { status: 500 }
    );
  }
}
